{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq language model with rnn\n",
    "# achtung: character-based!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial\n",
    "# https://www.tensorflow.org/tutorials/sequences/text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basis caparthy on rnns\n",
    "# http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Enable GPU acceleration to execute this notebook faster. \n",
    "# In Colab: Runtime > Change runtime type > Hardware acclerator > GPU. \n",
    "# If running locally make sure TensorFlow version >= 1.11. # => ok, is 1.13 in Mai 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /anaconda3\n",
      "db2_louvre               /anaconda3/envs/db2_louvre\n",
      "flaschenpost             /anaconda3/envs/flaschenpost\n",
      "mapsy                    /anaconda3/envs/mapsy\n",
      "reinforcement-learning     /anaconda3/envs/reinforcement-learning\n",
      "relevance_score          /anaconda3/envs/relevance_score\n",
      "tensorflow_text       *  /anaconda3/envs/tensorflow_text\n",
      "time-series-prediction     /anaconda3/envs/time-series-prediction\n",
      "twitter                  /anaconda3/envs/twitter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. read input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "# @param: domain\n",
    "domain = 'hitler_mein_kampf'\n",
    "path_to_file = os.path.join('originaltexte', domain + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'originaltexte/hitler_mein_kampf.txt'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ part of text: \n",
      "de große Bewegung auf dieser \n",
      "Erde ihr Wachsen\n",
      "\n",
      "+ length of text: 1569104, which corresponds to approx 1046 pages\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print(f'+ part of text: \\n{text[1234:1280]}')\n",
    "print(f'\\n+ length of text: {len(text)}, which corresponds to approx {round(len(text)/1500)} pages')\n",
    "# 1 din-a-4 Seite ca 1500 Zeichen => der shakespeare korpus umfasst ca 700 Seiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. create mapping char => int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vocab: 85\n",
      "vocab: ['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ä', 'Ö', 'Ü', 'ß', 'ä', 'ö', 'ü', '„']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'length of vocab: {len(vocab)}')\n",
    "print(f'vocab: {vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i,u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n' -> 0\n",
      "' ' -> 1\n",
      "'!' -> 2\n",
      "'\"' -> 3\n",
      "\"'\" -> 4\n",
      "'(' -> 5\n",
      "')' -> 6\n",
      "'*' -> 7\n",
      "',' -> 8\n",
      "'-' -> 9\n",
      "'.' -> 10\n",
      "'/' -> 11\n",
      "'0' -> 12\n",
      "'1' -> 13\n",
      "'2' -> 14\n",
      "'3' -> 15\n",
      "'4' -> 16\n",
      "'5' -> 17\n",
      "'6' -> 18\n",
      "'7' -> 19\n",
      "'8' -> 20\n",
      "'9' -> 21\n",
      "':' -> 22\n",
      "';' -> 23\n",
      "'?' -> 24\n",
      "'A' -> 25\n",
      "'B' -> 26\n",
      "'C' -> 27\n",
      "'D' -> 28\n",
      "'E' -> 29\n",
      "'F' -> 30\n",
      "'G' -> 31\n",
      "'H' -> 32\n",
      "'I' -> 33\n",
      "'J' -> 34\n",
      "'K' -> 35\n",
      "'L' -> 36\n",
      "'M' -> 37\n",
      "'N' -> 38\n",
      "'O' -> 39\n",
      "'P' -> 40\n",
      "'Q' -> 41\n",
      "'R' -> 42\n",
      "'S' -> 43\n",
      "'T' -> 44\n",
      "'U' -> 45\n",
      "'V' -> 46\n",
      "'W' -> 47\n",
      "'X' -> 48\n",
      "'Y' -> 49\n",
      "'Z' -> 50\n",
      "'a' -> 51\n",
      "'b' -> 52\n",
      "'c' -> 53\n",
      "'d' -> 54\n",
      "'e' -> 55\n",
      "'f' -> 56\n",
      "'g' -> 57\n",
      "'h' -> 58\n",
      "'i' -> 59\n",
      "'j' -> 60\n",
      "'k' -> 61\n",
      "'l' -> 62\n",
      "'m' -> 63\n",
      "'n' -> 64\n",
      "'o' -> 65\n",
      "'p' -> 66\n",
      "'q' -> 67\n",
      "'r' -> 68\n",
      "'s' -> 69\n",
      "'t' -> 70\n",
      "'u' -> 71\n",
      "'v' -> 72\n",
      "'w' -> 73\n",
      "'x' -> 74\n",
      "'y' -> 75\n",
      "'z' -> 76\n",
      "'Ä' -> 77\n",
      "'Ö' -> 78\n",
      "'Ü' -> 79\n",
      "'ß' -> 80\n",
      "'ä' -> 81\n",
      "'ö' -> 82\n",
      "'ü' -> 83\n",
      "'„' -> 84\n"
     ]
    }
   ],
   "source": [
    "for i, _ in zip(char2idx, range(len(idx2char))):\n",
    "    print(f'{repr(i)} -> {char2idx[i]}') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of the encoding: gshaft zu Landsberg am Lech anzutreten. \n",
      "\n",
      "Damit bot sich mir nach Jahren ununterbrochener Arbeit \n",
      "zum ersten Male die Möglichkei ---> [46 65 68 73 65 68 70  1  0  0 25 63  1]\n"
     ]
    }
   ],
   "source": [
    "print(f'This is an example of the encoding: {text[128:256]} ---> {text_as_int[:13]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. create Training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence prediction \n",
    "# e.g. input = Hello, targ_output = ello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6129"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "# TODO erhöhen, sollte am Ende z.B. ca 100 sein\n",
    "# @param sequence length\n",
    "seq_length = 256\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "examples_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V\n",
      "o\n",
      "r\n",
      "w\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "m\n",
      " \n",
      "1\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(15):\n",
    "    print(''.join(idx2char[i.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 65, 68, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n",
      "V\n",
      "o\n",
      "r\n",
      "w\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "m\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (257,), types: tf.int64>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(1):\n",
    "    print(str(len(item)))\n",
    "    \n",
    "    for element in item.numpy()[:13]:\n",
    "        print(str(idx2char[element]))\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_item_to_text(item):\n",
    "    return(''.join([str(idx2char[element]) for element in item.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sequence number 0:\n",
      "Vorwort \n",
      "\n",
      "Am 1. April 1924 hatte ich, auf Grund des Urteils- \n",
      "spruches des Münchner Volksgerichts von diesem Tage, \n",
      "meine Festungshaft zu Landsberg am Lech anzutreten. \n",
      "\n",
      "Damit bot sich mir nach Jahren ununterbrochener Arbeit \n",
      "zum ersten Male die Möglichkeit\n",
      "\n",
      "sequence number 1:\n",
      ", an ein Werk heran- \n",
      "zugehen, das von vielen gefordert und von mir selbst als \n",
      "zweckmäßig für die Bewegung empfunden wurde. So habe \n",
      "ich mich entschlossen, in zwei Bänden nicht nur die Ziele \n",
      "unserer Bewegung klarzulegen, sondern auch ein Bild der \n",
      "Entwick\n",
      "\n",
      "sequence number 2:\n",
      "lung derselben zu zeichnen. Aus ihr wird mehr zu \n",
      "lernen sein als aus jeder rein doktrinären Abhandlung. \n",
      "Ich hatte dabei auch die Gelegenheit, eine Darstellung \n",
      "meines eigenen Werdens zu geben, soweit dies zum Ver- \n",
      "ständnis sowohl des ersten als auch des \n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(sequences.take(3)):\n",
    "    print(f'\\nsequence number {idx}:')\n",
    "    print(''.join([str(idx2char[element]) for element in item.numpy()]))\n",
    "    #print(f'test: {sequence_item_to_text(item)}')\n",
    "#  print(repr(''.join([str(idx2char[item.numpy()][i]) for i in range(len(item))] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Hello' => 'Hell', 'ello'\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return(input_text, target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((256,), (256,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now construct whole datasate\n",
    "dataset = sequences.map(split_input_target)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "++ input: Vorwort \n",
      "\n",
      "Am 1. April 1924 hatte ich, auf Grund des Urteils- \n",
      "spruches des Münchner Volksgerichts von diesem Tage, \n",
      "meine Festungshaft zu Landsberg am Lech anzutreten. \n",
      "\n",
      "Damit bot sich mir nach Jahren ununterbrochener Arbeit \n",
      "zum ersten Male die Möglichkei\n",
      "\n",
      "++ output: orwort \n",
      "\n",
      "Am 1. April 1924 hatte ich, auf Grund des Urteils- \n",
      "spruches des Münchner Volksgerichts von diesem Tage, \n",
      "meine Festungshaft zu Landsberg am Lech anzutreten. \n",
      "\n",
      "Damit bot sich mir nach Jahren ununterbrochener Arbeit \n",
      "zum ersten Male die Möglichkeit\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    print('\\n')\n",
    "    print(f'\\n++ input: {sequence_item_to_text(input_text)}')\n",
    "    print(f'\\n++ output: {sequence_item_to_text(target_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 46 ('V')\n",
      "  expected output: 65 ('o')\n",
      "Step    1\n",
      "  input: 65 ('o')\n",
      "  expected output: 68 ('r')\n",
      "Step    2\n",
      "  input: 68 ('r')\n",
      "  expected output: 73 ('w')\n",
      "Step    3\n",
      "  input: 73 ('w')\n",
      "  expected output: 65 ('o')\n",
      "Step    4\n",
      "  input: 65 ('o')\n",
      "  expected output: 68 ('r')\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "        print(\"Step {:4d}\".format(i))\n",
    "        print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "        print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps per epoch : 191\n"
     ]
    }
   ],
   "source": [
    "# remember\n",
    "# seq_length = 100\n",
    "# examples_per_epoch = len(text)//seq_length\n",
    "# eine epoche bestetht aus ca 11T sequenzen, die in 174 batches von 64 durchgejagt werden\n",
    "\n",
    "#@param batch_size\n",
    "batch_size = 32\n",
    "\n",
    "# size for in_memory buffer where data is shuffeled\n",
    "BATCH_BUFFER = 10000\n",
    "\n",
    "steps_per_epoch = examples_per_epoch // batch_size\n",
    "print('steps per epoch : {:2d}'.format(steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "6129\n"
     ]
    }
   ],
   "source": [
    "print(seq_length)\n",
    "print(examples_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((32, 256), (32, 256)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle(BATCH_BUFFER).batch(batch_size, drop_remainder = True)\n",
    "\n",
    "# ich habe also batches je 64 sequenzen a 100 positionen\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((32, 256), (32, 256)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of vocab in chars\n",
    "vocab_size = len(idx2char)\n",
    "\n",
    "# the embedding dimension\n",
    "# @param embedding_dim, rnn_units, EPOCHS\n",
    "embedding_dim = 256\n",
    "\n",
    "# the number of rnn units\n",
    "rnn_units = 1024\n",
    "\n",
    "#number of epochs\n",
    "EPOCHS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no gpu\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    print('yes, gpu')\n",
    "    rnn = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "    print('no gpu')\n",
    "    import functools\n",
    "    rnn = functools.partial(\n",
    "        tf.keras.layers.GRU, recurrent_activation = 'sigmoid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    # TODO insert working GRU / RNN layer\n",
    "    # this does not work, will result in Tensor's shape (128, 128, 1024) is not compatible with supplied shape (128, 1024)\n",
    "    #tf.keras.layers.GRU\n",
    "    rnn(rnn_units, return_sequences=True, recurrent_initializer='glorot_uniform', stateful=True),\n",
    "    # tf.keras.layers.GRU(rnn_units, recurrent_activation = 'sigmoid', return_sequences=True, recurrent_initializer='glorot_uniform', stateful=True),\n",
    "    # tf.keras.layers.GRU(rnn_units),\n",
    "\n",
    "    tf.keras.layers.Dense(vocab_size)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (32, None, 256)           21760     \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (32, None, 1024)          3935232   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (32, None, 85)            87125     \n",
      "=================================================================\n",
      "Total params: 4,044,117\n",
      "Trainable params: 4,044,117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((32, 256), (32, 256)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256)\n",
      "(32, 256, 85) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "    print(input_example_batch.shape)\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(256), Dimension(85)])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro tip: sample instead of argmax!\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis = -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpret prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ Input: \n",
      " olkstums machen ohne Rücksicht auf \n",
      "die im einzelnen stattfindenden Kämpfe in rein wirtschaft- \n",
      "lichen Belangen. \n",
      "\n",
      "\n",
      "\n",
      "374 Die Nationalisierung der Massen \n",
      "\n",
      "Eine Bewegung, die den deutschen Arbeiter in ehrlicher \n",
      "Weise seinem Volke wiedergeben und dem intern\n",
      "\n",
      "++ True Output: \n",
      " lkstums machen ohne Rücksicht auf \n",
      "die im einzelnen stattfindenden Kämpfe in rein wirtschaft- \n",
      "lichen Belangen. \n",
      "\n",
      "\n",
      "\n",
      "374 Die Nationalisierung der Massen \n",
      "\n",
      "Eine Bewegung, die den deutschen Arbeiter in ehrlicher \n",
      "Weise seinem Volke wiedergeben und dem interna\n",
      "\n",
      "++ predicted Output: \n",
      "5d1M5pkI,OdG66Y7lÄ!3ÖV8(l28reK'ßßZkWR8dV;q17bö(\"e969IK*6p7\n",
      "-q2xqkPäWKrwdTS WUQ.EwXn\n",
      "7;*lP fwV/!Ud5t/V x\"3odYd3x y2„GGÜFZMYlEGen3LaJtJeqFb7w(hYüuw\n",
      "ü9L,PXöY6pWIü6: .Aog1KNZI9,SZOCk\"06:pD2l5CMgÖJ x4pyßx;c(GSiÖ tJ!„u1810IüMn;Säbc1ÄD\n",
      "VN*gV.c ÖhV'iVc!cj/2!KnRi,!\\›\n"
     ]
    }
   ],
   "source": [
    "input = ''.join(idx2char[input_example_batch[0]])\n",
    "print(f'++ Input: \\n {input}\\n')\n",
    "\n",
    "true_sequence = ''.join(idx2char[target_example_batch[0]])\n",
    "print(f'++ True Output: \\n {true_sequence}\\n')\n",
    "\n",
    "predicted_text = ''.join([idx2char[i] for i in sampled_indices])\n",
    "print(f'++ predicted Output: \\n{predicted_text}\\›')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(true_labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(true_labels, logits, from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss right now: [[4.450168  4.4398723 4.4438334 ... 4.4463215 4.4374223 4.4523654]\n",
      " [4.428007  4.447599  4.4567795 ... 4.444944  4.4476085 4.4371243]\n",
      " [4.4355445 4.4473233 4.4508204 ... 4.461235  4.4496975 4.4446683]\n",
      " ...\n",
      " [4.448326  4.437403  4.438001  ... 4.448039  4.4332156 4.4354463]\n",
      " [4.4472933 4.448262  4.4467645 ... 4.4381957 4.449739  4.4356427]\n",
      " [4.4433503 4.452824  4.4266977 ... 4.447014  4.4529724 4.443436 ]]\n",
      "mean scalar loss: 4.442293167114258\n"
     ]
    }
   ],
   "source": [
    "loss_first_try = loss(target_example_batch, example_batch_predictions)\n",
    "print(f'loss right now: {loss_first_try}')\n",
    "print(f'mean scalar loss: {loss_first_try.numpy().mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile with adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join('./training_checkpoints', domain)\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix,\n",
    "    save_weights_only = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "128/191 [===================>..........] - ETA: 16:50 - loss: 2.7136"
     ]
    }
   ],
   "source": [
    "# takes 12 mins per epoch. colab gup version only 12 secs\n",
    "\n",
    "# altes model laden und weiter trainieren\n",
    "continue_training = False\n",
    "if continue_training:\n",
    "    print('will continue training')\n",
    "    model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=32)\n",
    "    model.compile(optimizer = tf.train.AdamOptimizer(), loss = loss)\n",
    "    model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "history = model.fit(dataset.repeat(), epochs = EPOCHS, steps_per_epoch = steps_per_epoch, callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.callbacks.History"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.077462083414981, 2.95939470592298, 2.6221059498034025, 2.433696194698936, 2.6055086286444413, 2.1903584003448486, 2.087346817317762, 1.994315831284774, 1.904001794363323, 1.8167793562537746, 1.7335980063990544, 1.650940173550656, 1.5804095519216437, 1.5114201809230603, 1.449017461977507, 1.3849976062774658, 1.3285146637966758, 1.2723219394683838, 1.2193829134890908, 1.1675028863706087, 1.1176011813314337, 1.0664370185450505, 1.0147384781586497, 0.9691499879485682, 0.916933116159941, 0.8648003277025724, 0.8111133042134737, 0.7590943669017992, 0.7117609726755243, 0.6644816555474934, 0.6128065586090088, 0.5633275352026287]\n"
     ]
    }
   ],
   "source": [
    "loss_history = history.history['loss']\n",
    "print(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: warum hängt das hier immer?\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': None,\n",
       " 'epochs': 32,\n",
       " 'steps': 19,\n",
       " 'samples': 19,\n",
       " 'verbose': 1,\n",
       " 'do_validation': False,\n",
       " 'metrics': ['loss']}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints_marx_manifest/ckpt_32'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0xbca050400>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size = 1 to keep model simple\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (1, None, 256)            22784     \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (1, None, 1024)           3935232   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (1, None, 89)             91225     \n",
      "=================================================================\n",
      "Total params: 4,049,241\n",
      "Trainable params: 4,049,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wofür das hier?\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text (model, start_string, temperature, out_len):\n",
    "    \n",
    "    # model input\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    # result list\n",
    "    generated_text = []\n",
    "    \n",
    "\n",
    "    \n",
    "    # reset model\n",
    "    model.reset_states()\n",
    "    \n",
    "    # predict char per char\n",
    "    for i in range(out_len):\n",
    "        \n",
    "        # generate first prediction (prob Distribution) from start string\n",
    "        # predicted_id wird dabei jedes mal an input_eval angehängkt\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # now draw sample from probability Distribution\n",
    "        # temperatrue hat deutlichen einfluss. 1 ist guter wert\n",
    "        predictions = predictions / temperature #?? Sinn? Scheint ne reine Skalierung zu sein, hat die überhaupt einen Effekt?\n",
    "        predicted_id = tf.multinomial(predictions, num_samples = 1)[-1,0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        generated_text.append(predicted_id)\n",
    "    \n",
    "    return(''.join([idx2char[i] for i in generated_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the higher the temp the more chaotic the predicted sentence\n",
    "temperature = 0.4\n",
    "\n",
    "# how much text should be produced?\n",
    "out_len =2000\n",
    "\n",
    "#start string\n",
    "start_string = 'D'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dem in englische Restaurationszeit 1660-1680, sondern in der erzwungenen Arbeiter in einfache Herrschaft der Industrieller Inderessen des gesamten bestand der Industrie verwandelt werden.\n",
      "\n",
      "An die Stelle der herrschenden Klasse ins Proletariat eine Wirklichkeit, der deutsche Sozialismus\n",
      "Der deutsche oder \"wahre\" Sozialismus\n",
      "Der deutsche Einistung der Produktion und der Anterung der unmittelbare Erscheinung der Arbeiter entgegengenet ter alten Gesellschaft zu sprechen, und damit aller Literatur und Kampfliche Freiheit versteckten sich die gesellschaftlichen Parteien nur daben sie die ganze bestehen von Engels\n",
      "\n",
      "Schaftliche Gewalt einer Klasse vereint und das Kapital selbständig und unter der Arbeiter und der politischen Ideen einer Klasse gegen die Bourgeoisie hat nicht nur das Proletariat die Klasse gesellschaftliche Produkte, die in ihrer proletarischen Bevölkerung aller pilitischen Klassen. Was alle deutsche Ausgabe 1872)\n",
      "Vorwort (deutsche Ausgabe 1872)\n",
      "Vorwort (italienische Ausgabe 1882)\n",
      "Vorwort (italienische Ausgabe 1872)\n",
      "Vorwort (deutsche Ausgabe 1892)\n",
      "Vorwort (deutsche Ausgabe von 1888.] <=\n",
      "\n",
      "(8) Die Geschichte von den Arbeiter selbst mit der Entwicklung der Industrie zurückgeführt.\n",
      "\n",
      "Die Bourgeoisie hat entwickle der Industrieller der Entwicklung der Industrie zur Werfteu (6) in Deutschland von den Angekturg vermehren.\n",
      "\n",
      "Alle bisherige Aneignung der Arbeiter der Gesellschaft in den Händen des Klassengegensatzes sich entwickelten sich die französische Revolution ist die Aussetzung aller Länder. In einem Wort, die Michtliche Stelle und noch {22} von den übrigen proletarischen Lebensbedingungen des Proletariats zur Klasse gegen die Bourgeoisie selbst.\n",
      "\n",
      "Aber im Interesse der arbeitenden Klasse anschließt, der Klassenkampf zu verlieren. Aufliche Verhältnis zur geschichtlichen Entwicklungsgange aufgehoben. Aller und vor allem ihren aufgeblähte bestampt die gesellschaftlichen Produktionsverhältnisse auf der Arbeiter verliegen und Abschaffung des Eigentums zeiglische Arbei\n"
     ]
    }
   ],
   "source": [
    "generated_string = generate_text(model, start_string, temperature, out_len)\n",
    "with open (os.path.join('generierte_texte', domain + '_' + start_string +'.txt'), 'w') as file:\n",
    "    file.write(start_string + generated_string)\n",
    "\n",
    "print(start_string +generated_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
